import streamlit as st
import json
import os
from datetime import datetime
import time
import requests
from bs4 import BeautifulSoup
import re

# LangChain imports
try:
    from langchain_openai import ChatOpenAI
    from langchain_anthropic import ChatAnthropic
    from langchain_community.llms import HuggingFaceHub
    from langchain_huggingface import HuggingFaceEndpoint
except ImportError:
    st.error("Please install: pip install langchain langchain-anthropic langchain-openai langchain-huggingface")
    st.stop()

# Page config
st.set_page_config(
    page_title="LinkedIn Multi-Agent Optimizer",
    page_icon="üíº",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
.agent-box {
    padding: 20px;
    border-radius: 10px;
    margin: 10px 0;
    border-left: 5px solid;
}
.agent1 { border-left-color: #3b82f6; background-color: #eff6ff; }
.agent2 { border-left-color: #10b981; background-color: #ecfdf5; }
.agent3 { border-left-color: #8b5cf6; background-color: #f5f3ff; }
.agent4 { border-left-color: #f59e0b; background-color: #fffbeb; }
.success-box {
    padding: 15px;
    background-color: #d1fae5;
    border-radius: 8px;
    border-left: 4px solid #10b981;
}
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'profile_data' not in st.session_state:
    st.session_state.profile_data = {}
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = {}
if 'agent_logs' not in st.session_state:
    st.session_state.agent_logs = []

# Data directory
DATA_DIR = "linkedin_data"
os.makedirs(DATA_DIR, exist_ok=True)

def llm_generate(llm, prompt):
    """Universal LLM generation - works with both old and new LangChain versions"""
    # Demo mode - return template responses
    if llm == "demo":
        if "Remote-Readiness Score" in prompt:
            return """**Remote-Readiness Score: 75/100**

**Key Strengths:**
- Good technical background
- Relevant experience

**Critical Gaps:**
- Missing remote work keywords
- Needs more specific achievements

**Missing Keywords:**
- Remote, Distributed, Virtual collaboration
- ServiceNow certifications
- Gen AI, Machine Learning

**Top 5 Improvements:**
1. Add remote work experience
2. Highlight ServiceNow modules
3. Include Gen AI projects
4. Add quantifiable results
5. Update skills section

(Demo mode - using template response)"""
        else:
            return f"[Demo Mode Response]\n\nThis is a template response. For real AI-powered analysis, please:\n1. Get a free Hugging Face token\n2. Select Hugging Face provider\n3. Enter your token\n\n{prompt[:200]}..."
    
    try:
        # Check if it's HuggingFaceHub (uses different API)
        if hasattr(llm, 'client'):
            # HuggingFaceHub uses __call__ or direct invocation
            try:
                response = llm(prompt)
                return str(response)
            except Exception as e:
                st.error(f"HuggingFace API Error: {str(e)}")
                return ""
        
        # Try new API (invoke) for ChatOpenAI/ChatAnthropic
        response = llm.invoke(prompt)
        # Handle different response types
        if hasattr(response, 'content'):
            return response.content
        return str(response)
    except AttributeError:
        try:
            # Try direct call
            response = llm(prompt)
            if hasattr(response, 'content'):
                return response.content
            return str(response)
        except Exception as e:
            st.error(f"LLM Call Error: {str(e)}")
            return ""
    except Exception as e:
        st.error(f"LLM Error: {str(e)}")
        st.write("üí° Troubleshooting:")
        st.write("- Check your API key/token is valid")
        st.write("- Try a different model")
        st.write("- For Hugging Face: Some models may have rate limits")
        return ""

def extract_linkedin_from_url(url, llm):
    """Extract LinkedIn profile from URL"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        for script in soup(["script", "style"]):
            script.decompose()
        
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = '\n'.join(chunk for chunk in chunks if chunk)
        text = text[:8000]
        
        prompt = f"Extract LinkedIn profile info from this text:\n\n{text}\n\nProvide: headline, about, experience, skills"
        extracted = llm_generate(llm, prompt)
        
        return {'success': True, 'extracted_text': extracted, 'url': url}
    except Exception as e:
        return {'success': False, 'error': str(e), 'message': 'Unable to fetch. Use manual input.'}

def parse_extracted_profile(extracted_text, llm):
    """Parse extracted text into fields"""
    prompt = f"""Parse this into JSON with fields: headline, about, experience, skills

{extracted_text}

Return only JSON, no other text."""
    
    try:
        parsed = llm_generate(llm, prompt)
        parsed = re.sub(r'```json\s*|\s*```', '', parsed).strip()
        return json.loads(parsed)
    except:
        return {
            'headline': 'See raw data',
            'about': extracted_text,
            'experience': 'See raw data',
            'skills': 'See raw data'
        }

class LinkedInAgent:
    """Base agent class"""
    def __init__(self, name, role, llm):
        self.name = name
        self.role = role
        self.llm = llm
    
    def log_activity(self, message):
        st.session_state.agent_logs.append({
            "agent": self.name,
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "message": message
        })

class Agent1_Analyzer(LinkedInAgent):
    """Agent 1: Initial Analyzer"""
    def execute(self, profile_data, context=None):
        self.log_activity("Starting analysis...")
        
        prompt = f"""Analyze this LinkedIn profile for remote {profile_data.get('target_role', 'job')}:

Headline: {profile_data.get('headline', 'N/A')}
About: {profile_data.get('about', 'N/A')}
Experience: {profile_data.get('experience', 'N/A')}
Skills: {profile_data.get('skills', 'N/A')}

Provide:
1. Remote-Readiness Score (0-100)
2. Key Strengths
3. Critical Gaps
4. Missing Keywords
5. Top 5 Improvements"""
        
        response = llm_generate(self.llm, prompt)
        self.log_activity("Analysis complete")
        return response

class Agent2_ReAnalyzer(LinkedInAgent):
    """Agent 2: Re-Analyzer"""
    def execute(self, profile_data, context=None):
        self.log_activity("Re-analyzing...")
        
        agent1_result = context.get('agent1_result', '')
        prompt = f"""Review this analysis:

{agent1_result}

Provide:
1. Validation/challenges
2. Overlooked opportunities
3. Alternative approaches
4. Market insights"""
        
        response = llm_generate(self.llm, prompt)
        self.log_activity("Re-analysis complete")
        return response

class Agent3_Rewriter(LinkedInAgent):
    """Agent 3: Profile Rewriter"""
    def execute(self, profile_data, context=None):
        self.log_activity("Rewriting profile...")
        
        agent1 = context.get('agent1_result', '')
        agent2 = context.get('agent2_result', '')
        
        prompt = f"""Create optimized LinkedIn profile for remote {profile_data.get('target_role')}:

Current Profile:
{profile_data.get('headline', 'N/A')}
{profile_data.get('about', 'N/A')}

Analysis:
{agent1}
{agent2}

Provide:
1. NEW HEADLINE (120 chars)
2. NEW ABOUT (2-3 paragraphs)
3. EXPERIENCE BULLETS (optimized)
4. SKILLS LIST (15-20 skills)
5. ADDITIONAL TIPS"""
        
        response = llm_generate(self.llm, prompt)
        self.log_activity("Rewrite complete")
        return response

class Agent4_Reviewer(LinkedInAgent):
    """Agent 4: Quality Reviewer"""
    def execute(self, profile_data, context=None):
        self.log_activity("Final review...")
        
        rewritten = context.get('agent3_result', '')
        prompt = f"""Review this optimized profile:

{rewritten}

Provide:
1. Quality Score (0-100)
2. Strengths
3. Remaining Issues
4. Keyword Analysis
5. ATS Compatibility
6. Final Recommendations"""
        
        response = llm_generate(self.llm, prompt)
        self.log_activity("Review complete")
        return response

def initialize_llm(provider, api_key, hf_model=None):
    """Initialize LLM"""
    if provider == "Demo Mode (No API - Limited)":
        return "demo"  # Return demo flag
    
    if not api_key or api_key.strip() == "":
        st.error("‚ùå API key is empty! Please enter your API key in the sidebar.")
        return None
    
    try:
        if provider == "OpenAI":
            return ChatOpenAI(temperature=0.7, model_name="gpt-4o-mini", api_key=api_key)
        elif provider == "Anthropic":
            return ChatAnthropic(temperature=0.7, model_name="claude-3-5-sonnet-20241022", api_key=api_key)
        elif provider == "Hugging Face (Free)":
            # Use selected model or default
            model = hf_model or "mistralai/Mistral-7B-Instruct-v0.2"
            st.info(f"ü§ó Using model: {model}")
            return HuggingFaceHub(
                repo_id=model,
                huggingfacehub_api_token=api_key,
                model_kwargs={"temperature": 0.7, "max_length": 2000, "max_new_tokens": 512}
            )
    except Exception as e:
        st.error(f"‚ùå Error initializing LLM: {str(e)}")
        st.error("üí° Troubleshooting tips:")
        st.write("- Check your API key is correct")
        st.write("- For Hugging Face: Make sure you have a valid token from https://huggingface.co/settings/tokens")
        st.write("- Try selecting a different model")
        return None

def run_multi_agent_system(profile_data, llm):
    """Run multi-agent analysis"""
    st.session_state.agent_logs = []
    results = {}
    
    agent1 = Agent1_Analyzer("Agent 1", "Analyzer", llm)
    agent2 = Agent2_ReAnalyzer("Agent 2", "Re-Analyzer", llm)
    agent3 = Agent3_Rewriter("Agent 3", "Rewriter", llm)
    agent4 = Agent4_Reviewer("Agent 4", "Reviewer", llm)
    
    progress = st.progress(0)
    status = st.empty()
    
    try:
        status.markdown("### Agent 1: Analyzing...")
        progress.progress(25)
        results['agent1'] = agent1.execute(profile_data)
        time.sleep(0.5)
        
        status.markdown("### Agent 2: Re-analyzing...")
        progress.progress(50)
        results['agent2'] = agent2.execute(profile_data, {'agent1_result': results['agent1']})
        time.sleep(0.5)
        
        status.markdown("### Agent 3: Rewriting...")
        progress.progress(75)
        results['agent3'] = agent3.execute(profile_data, {
            'agent1_result': results['agent1'],
            'agent2_result': results['agent2']
        })
        time.sleep(0.5)
        
        status.markdown("### Agent 4: Reviewing...")
        progress.progress(100)
        results['agent4'] = agent4.execute(profile_data, {'agent3_result': results['agent3']})
        
        status.markdown("### ‚úÖ Complete!")
        return results
    except Exception as e:
        st.error(f"Error in multi-agent system: {e}")
        return None

def save_data(data, filename):
    """Save to JSON"""
    path = os.path.join(DATA_DIR, filename)
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    return path

def load_data(filename):
    """Load from JSON"""
    path = os.path.join(DATA_DIR, filename)
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

def main():
    st.title("üíº LinkedIn Multi-Agent Optimizer")
    st.markdown("### üîí Private & Offline - Data stays on your computer")
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        provider = st.selectbox("AI Provider", [
            "Hugging Face (Free)", 
            "OpenAI", 
            "Anthropic",
            "Demo Mode (No API - Limited)"
        ])
        
        # Hugging Face model selection
        hf_model = None
        if provider == "Demo Mode (No API - Limited)":
            st.warning("‚ö†Ô∏è Demo mode provides basic template responses without AI")
            st.caption("Use this to test the app workflow")
            api_key = "demo_mode"  # Dummy key for demo
        elif provider == "Hugging Face (Free)":
            st.success("üÜì 100% Free API")
            st.info("Get token: https://huggingface.co/settings/tokens")
            st.caption("Click 'New token' ‚Üí Select 'Read' ‚Üí Generate ‚Üí Copy")
            
            hf_model = st.selectbox(
                "Select Model",
                [
                    "mistralai/Mistral-7B-Instruct-v0.2",
                    "google/flan-t5-xxl",
                    "meta-llama/Llama-2-7b-chat-hf",
                    "HuggingFaceH4/zephyr-7b-beta"
                ],
                help="Mistral-7B recommended for best quality"
            )
            st.caption("‚≠ê Mistral-7B: Best quality")
            st.caption("‚ö° FLAN-T5: Fastest")
        
        api_key = st.text_input(
            f"{provider} API Key", 
            type="password",
            help="Paste your API key here",
            disabled=(provider == "Demo Mode (No API - Limited)")
        )
        
        if provider == "OpenAI":
            st.info("https://platform.openai.com/api-keys")
        elif provider == "Anthropic":
            st.info("https://console.anthropic.com/")
        
        st.divider()
        
        # Test API connection
        if api_key and st.button("üß™ Test API Connection"):
            with st.spinner("Testing..."):
                if provider == "Hugging Face (Free)":
                    test_llm = initialize_llm(provider, api_key, hf_model)
                else:
                    test_llm = initialize_llm(provider, api_key)
                
                if test_llm:
                    test_result = llm_generate(test_llm, "Say 'Hello' in one word.")
                    if test_result:
                        st.success("‚úÖ API Connected!")
                        st.write(f"Response: {test_result}")
                    else:
                        st.error("‚ùå API call failed")
                else:
                    st.error("‚ùå Failed to initialize")
        
        st.divider()
        st.header("üíæ Data")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üíæ Save"):
                if st.session_state.profile_data:
                    save_data(st.session_state.profile_data, "profile_data.json")
                    st.success("Saved!")
        
        with col2:
            if st.button("üìÇ Load"):
                data = load_data("profile_data.json")
                if data:
                    st.session_state.profile_data = data
                    st.success("Loaded!")
                    st.rerun()
        
        st.code(os.path.abspath(DATA_DIR))
    
    # Tabs
    tab1, tab2, tab3 = st.tabs(["üìù Input", "ü§ñ Analysis", "üìä Results"])
    
    with tab1:
        st.header("Profile Information")
        
        # Target Role - ALWAYS VISIBLE at top
        st.markdown("### üéØ Your Target Position")
        target_role = st.text_input(
            "Target Remote Role (Required) *",
            value=st.session_state.profile_data.get('target_role', ''),
            placeholder="e.g., ServiceNow Developer, Gen AI Engineer, ServiceNow Architect",
            help="Specify your target remote position. Examples: 'ServiceNow Developer - Gen AI', 'Senior ServiceNow Engineer', 'AI/ML Engineer - ServiceNow Platform'",
            key="target_role_input"
        )
        
        # Update target role in session state immediately
        if target_role:
            if 'profile_data' not in st.session_state:
                st.session_state.profile_data = {}
            st.session_state.profile_data['target_role'] = target_role
        
        # Show helpful suggestions for ServiceNow + Gen AI
        if 'servicenow' in target_role.lower() or 'genai' in target_role.lower() or 'gen ai' in target_role.lower():
            st.success("‚úÖ Great choice! ServiceNow + Gen AI is a hot combination for remote roles")
            with st.expander("üí° Tips for ServiceNow + Gen AI Remote Positions"):
                st.markdown("""
                **Key Skills to Highlight:**
                - ServiceNow platform expertise (ITSM, ITOM, CSM, etc.)
                - Gen AI integration with ServiceNow
                - Virtual Agent & Chatbot development
                - Predictive Intelligence
                - Flow Designer & Integration Hub
                - Remote collaboration tools
                - Agile/Scrum methodologies
                
                **Keywords to Include:**
                - "Remote", "Distributed team", "Virtual collaboration"
                - "ServiceNow certified" (mention certifications)
                - "Gen AI", "Machine Learning", "AI/ML"
                - "Automation", "Intelligent workflows"
                - "API integration", "REST/SOAP"
                """)
        
        st.divider()
        
        # Show multiple methods to get LinkedIn data
        st.info("üîê **You're logged into LinkedIn?** Perfect! Choose the easiest method:")
        
        method = st.radio(
            "Choose Import Method:",
            ["üìã Copy-Paste (Easiest)", "üîó Browser Console (Auto-Extract)", "üìÑ LinkedIn PDF Export", "üåê URL Scraper (May Fail)"],
            horizontal=True
        )
        
        st.divider()
        
        # Method 1: Copy-Paste (Recommended)
        if method == "üìã Copy-Paste (Easiest)":
            st.subheader("üìã Copy-Paste Method (Recommended)")
            
            with st.expander("üìñ How to Copy Your LinkedIn Profile", expanded=True):
                st.markdown("""
                ### Step-by-Step Instructions:
                
                1. **Open your LinkedIn profile** in another tab
                2. **Copy each section** individually:
                   - **Headline**: Click on your name area ‚Üí Copy the text under your name
                   - **About**: Scroll to "About" section ‚Üí Click "Show more" ‚Üí Select all ‚Üí Copy
                   - **Experience**: Copy your recent job descriptions (especially ServiceNow & Gen AI work!)
                   - **Skills**: Copy the skills list (emphasize ServiceNow, Gen AI, AI/ML skills)
                
                3. **Paste below** in the corresponding fields
                
                üí° **Tip**: Keep your LinkedIn tab open while filling this form!
                """)
            
            with st.form("manual_form"):
                headline = st.text_area("üìå Current Headline",
                    value=st.session_state.profile_data.get('headline', ''),
                    placeholder="Paste your LinkedIn headline here (e.g., 'ServiceNow Developer | Gen AI Enthusiast')",
                    height=80,
                    help="The text that appears right under your name on LinkedIn")
                
                about = st.text_area("üìÑ About Section",
                    value=st.session_state.profile_data.get('about', ''),
                    placeholder="Paste your entire About/Summary section here - highlight your ServiceNow and Gen AI experience",
                    height=200,
                    help="Your LinkedIn 'About' or 'Summary' section - click 'Show more' to see all")
                
                experience = st.text_area("üíº Recent Experience",
                    value=st.session_state.profile_data.get('experience', ''),
                    placeholder="Paste your ServiceNow and Gen AI-related work experience (title, company, description)",
                    height=150,
                    help="Copy 1-2 most recent job entries, especially those involving ServiceNow or Gen AI")
                
                skills = st.text_area("üõ†Ô∏è Skills",
                    value=st.session_state.profile_data.get('skills', ''),
                    placeholder="ServiceNow, Gen AI, Python, JavaScript, Flow Designer, Integration Hub, Machine Learning, etc.",
                    height=100,
                    help="List skills separated by commas - include ServiceNow modules, certifications, Gen AI tools")
                
                submit = st.form_submit_button("üíæ Save Profile Data", use_container_width=True)
                
                if submit:
                    st.session_state.profile_data.update({
                        'headline': headline,
                        'about': about,
                        'experience': experience,
                        'skills': skills,
                        'timestamp': datetime.now().isoformat()
                    })
                    st.success("‚úÖ Profile data saved!")
        
        # Method 2: Browser Extension
        elif method == "üîó Browser Console (Auto-Extract)":
            st.subheader("üîó Browser Console Auto-Extract")
            
            with st.expander("üìñ How to Auto-Extract Using Browser Console", expanded=True):
                st.markdown("""
                ### Automatic Extraction (1-Click):
                
                1. **Open your LinkedIn profile** in Chrome/Edge/Firefox
                2. **Press F12** to open Developer Tools
                3. **Click "Console" tab**
                4. **Copy and paste this code** then press Enter:
                """)
                
                st.code("""
// LinkedIn Profile Auto-Extractor for ServiceNow + Gen AI roles
const data = {
    headline: document.querySelector('.text-body-medium')?.innerText || 
              document.querySelector('.top-card-layout__headline')?.innerText || '',
    about: document.querySelector('.pv-about__summary-text')?.innerText || 
           document.querySelector('.display-flex.ph5.pv3')?.innerText || '',
    experience: Array.from(document.querySelectorAll('.pvs-list__item--line-separated'))
        .slice(0, 2)
        .map(e => e.innerText)
        .join('\\n\\n') || '',
    skills: Array.from(document.querySelectorAll('.pvs-skill-category-entity__name'))
        .map(s => s.innerText)
        .join(', ') || ''
};
copy(JSON.stringify(data, null, 2));
alert('‚úÖ LinkedIn data copied to clipboard! Paste it in the app now.');
console.log('Extracted data:', data);
                """, language="javascript")
                
                st.markdown("""
                5. **Data is automatically copied!** Paste in the text area below
                6. Click "Import JSON Data"
                
                üí° **This extracts everything automatically in 1 second!**
                """)
            
            json_input = st.text_area(
                "Paste extracted JSON data here:",
                height=200,
                placeholder='{"headline": "...", "about": "...", "experience": "...", "skills": "..."}',
                help="After running the console code, paste the copied JSON here"
            )
            
            if st.button("üì• Import JSON Data", use_container_width=True, type="primary"):
                try:
                    data = json.loads(json_input)
                    st.session_state.profile_data.update({
                        'headline': data.get('headline', ''),
                        'about': data.get('about', ''),
                        'experience': data.get('experience', ''),
                        'skills': data.get('skills', ''),
                    })
                    st.success("‚úÖ Data imported successfully! Scroll down to start analysis.")
                    st.rerun()
                except json.JSONDecodeError:
                    st.error("‚ùå Invalid JSON format. Make sure you copied the entire output from console.")
                except Exception as e:
                    st.error(f"‚ùå Error: {e}")
        
        # Method 3: PDF Export
        elif method == "üìÑ LinkedIn PDF Export":
            st.subheader("üìÑ LinkedIn PDF Export Method")
            
            with st.expander("üìñ How to Export Your Profile as PDF", expanded=True):
                st.markdown("""
                ### Export LinkedIn Profile:
                
                1. **Go to your LinkedIn profile**
                2. **Click "More"** button (three dots)
                3. **Select "Save to PDF"**
                4. **Download the PDF**
                5. **Upload it below**
                
                The AI will extract text from your PDF and parse it automatically!
                """)
            
            uploaded_file = st.file_uploader(
                "Upload LinkedIn PDF",
                type=['pdf'],
                help="Upload the PDF exported from LinkedIn"
            )
            
            if uploaded_file:
                if not api_key:
                    st.warning("‚ö†Ô∏è Enter your API key in the sidebar first!")
                elif st.button("üîç Extract from PDF", use_container_width=True, key="extract_pdf_btn"):
                    with st.spinner("üìÑ Extracting text from PDF..."):
                        try:
                            # Read PDF
                            import PyPDF2
                            pdf_reader = PyPDF2.PdfReader(uploaded_file)
                            text = ""
                            for page in pdf_reader.pages:
                                text += page.extract_text()
                            
                            st.info(f"‚úÖ Extracted {len(text)} characters from PDF")
                            
                            # Use AI to parse
                            if provider == "Hugging Face (Free)":
                                llm = initialize_llm(provider, api_key, hf_model)
                            else:
                                llm = initialize_llm(provider, api_key)
                            
                            if llm:
                                with st.spinner("ü§ñ AI is parsing your profile..."):
                                    parsed = parse_extracted_profile(text, llm)
                                    st.session_state.profile_data.update({
                                        'headline': parsed.get('headline', ''),
                                        'about': parsed.get('about', ''),
                                        'experience': parsed.get('experience', ''),
                                        'skills': parsed.get('skills', ''),
                                    })
                                    st.success("‚úÖ PDF processed successfully! Review the data below:")
                                    st.json(parsed)
                                    st.info("üìù Scroll down to see your extracted data or go to the Analysis tab!")
                            else:
                                st.error("‚ùå Failed to initialize AI model")
                                
                        except ImportError:
                            st.error("‚ùå PyPDF2 not installed. Run: pip install PyPDF2")
                        except Exception as e:
                            st.error(f"‚ùå Error processing PDF: {e}")
        
        # Method 4: URL Scraper
        else:
            st.subheader("üåê URL Scraper (Limited - May Not Work)")
            
            with st.expander("‚ö†Ô∏è Important Limitations", expanded=True):
                st.markdown("""
                ### Why URL Scraping Often Fails:
                
                - ‚ùå LinkedIn blocks automated scraping
                - ‚ùå Requires login to see full profiles
                - ‚ùå Profile must be public
                - ‚ùå Anti-bot protection
                
                ### Better Alternatives:
                1. Use **Copy-Paste method** (easiest!)
                2. Use **Browser Extension method** (most complete)
                3. Use **PDF Export** (official LinkedIn feature)
                
                ‚ö†Ô∏è **Only try this if your profile is fully public**
                """)
            
            with st.form("url_form"):
                url = st.text_input("LinkedIn URL", placeholder="https://linkedin.com/in/yourprofile")
                
                import_btn = st.form_submit_button("üîç Try Extraction", use_container_width=True)
                
                if import_btn:
                    if not url:
                        st.error("‚ùå Please enter a LinkedIn URL!")
                    elif not api_key:
                        st.error("‚ùå Enter API key in sidebar first!")
                    else:
                        with st.spinner("üåê Attempting to extract... (This may fail)"):
                            if provider == "Hugging Face (Free)":
                                llm = initialize_llm(provider, api_key, hf_model)
                            else:
                                llm = initialize_llm(provider, api_key)
                            
                            if llm:
                                result = extract_linkedin_from_url(url, llm)
                                if result['success']:
                                    with st.spinner("ü§ñ Parsing extracted data..."):
                                        parsed = parse_extracted_profile(result['extracted_text'], llm)
                                        st.session_state.profile_data.update({
                                            'headline': parsed.get('headline', ''),
                                            'about': parsed.get('about', ''),
                                            'experience': parsed.get('experience', ''),
                                            'skills': parsed.get('skills', ''),
                                        })
                                        st.success("‚úÖ Extracted successfully! (Rare success)")
                                        st.json(parsed)
                                        st.info("üìù Data saved! Go to Analysis tab to continue.")
                                else:
                                    st.error("‚ùå Extraction failed (expected). LinkedIn blocks automated scraping.")
                                    st.info("üí° Please use the 'Copy-Paste (Easiest)' method instead!")
                            else:
                                st.error("‚ùå Failed to initialize AI model")
        
        if st.session_state.profile_data:
            st.divider()
            st.success("‚úÖ Profile data loaded! Go to the 'ü§ñ Analysis' tab to run the agents.")
            
            # Quick preview
            with st.expander("üìã Preview Your Data"):
                st.write("**Target Role:**", st.session_state.profile_data.get('target_role', 'Not set'))
                st.write("**Headline:**", st.session_state.profile_data.get('headline', 'Not set')[:100] + "...")
                st.write("**About:**", st.session_state.profile_data.get('about', 'Not set')[:200] + "...")
                st.write("**Experience:**", st.session_state.profile_data.get('experience', 'Not set')[:200] + "...")
                st.write("**Skills:**", st.session_state.profile_data.get('skills', 'Not set')[:100] + "...")
    
    with tab2:
        st.header("ü§ñ Multi-Agent Analysis")
        
        # Check prerequisites
        if not api_key:
            st.error("‚ö†Ô∏è Please enter your API key in the sidebar first!")
            st.stop()
        
        if not st.session_state.profile_data:
            st.warning("‚ö†Ô∏è Please enter your profile data in the 'üìù Input' tab first!")
            st.stop()
        
        if not st.session_state.profile_data.get('target_role'):
            st.error("‚ö†Ô∏è Please enter your target role in the 'üìù Input' tab first!")
            st.stop()
        
        # Show profile summary
        st.info(f"üéØ Target Role: **{st.session_state.profile_data.get('target_role')}**")
        
        # Run button
        if st.button("‚ñ∂Ô∏è Run Multi-Agent Analysis", type="primary", use_container_width=True, key="run_analysis_btn"):
            # Pass hf_model if using Hugging Face
            if provider == "Hugging Face (Free)":
                llm = initialize_llm(provider, api_key, hf_model)
            else:
                llm = initialize_llm(provider, api_key)
            
            if llm:
                with st.spinner("ü§ñ Agents are working..."):
                    results = run_multi_agent_system(st.session_state.profile_data, llm)
                    if results:
                        st.session_state.analysis_results = results
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        save_data({
                            'profile': st.session_state.profile_data,
                            'results': results,
                            'timestamp': datetime.now().isoformat()
                        }, f'results_{timestamp}.json')
                        st.success("‚úÖ Analysis complete! Check the 'üìä Results' tab!")
                        st.balloons()
            else:
                st.error("‚ùå Failed to initialize AI model. Check your API key!")
        
        if st.session_state.agent_logs:
            st.divider()
            st.subheader("üìã Activity Log")
            for log in st.session_state.agent_logs:
                agent_num = log['agent'].split()[1]
                st.markdown(f"""
                <div class="agent-box agent{agent_num}">
                    <strong>{log['agent']}</strong> [{log['timestamp']}]<br>
                    {log['message']}
                </div>
                """, unsafe_allow_html=True)
    
    with tab3:
        st.header("üìä Results")
        
        if not st.session_state.analysis_results:
            st.info("Run analysis first")
        else:
            results = st.session_state.analysis_results
            
            with st.expander("üîç Agent 1: Analysis", expanded=True):
                st.markdown(results.get('agent1', ''))
            
            with st.expander("üîÑ Agent 2: Re-Analysis"):
                st.markdown(results.get('agent2', ''))
            
            st.divider()
            st.subheader("‚ú® Optimized Profile")
            st.markdown("""
            <div class="success-box">
                üìù Copy and paste into your LinkedIn!
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown(results.get('agent3', ''))
            
            with st.expander("üîé Agent 4: Quality Review"):
                st.markdown(results.get('agent4', ''))
            
            st.divider()
            st.subheader("üîß Modification Guide")
            
            if st.button("üìã Generate Guide", use_container_width=True):
                with st.spinner("Generating..."):
                    if provider == "Hugging Face (Free)":
                        llm = initialize_llm(provider, api_key, hf_model)
                    else:
                        llm = initialize_llm(provider, api_key)
                    if llm:
                        prompt = f"""Create step-by-step LinkedIn update guide:

{results.get('agent3', '')}

Format as numbered checklist with:
1. Headline changes
2. About updates
3. Experience bullets
4. Skills to add
5. Quick wins"""
                        
                        guide = llm_generate(llm, prompt)
                        st.markdown(guide)
                        
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        path = os.path.join(DATA_DIR, f'guide_{timestamp}.txt')
                        with open(path, 'w', encoding='utf-8') as f:
                            f.write(guide)
                        st.success(f"Saved: {path}")
            
            st.divider()
            st.subheader("üíæ Export")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üìÑ Export TXT", use_container_width=True):
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    content = f"""OPTIMIZED PROFILE
{results.get('agent3', '')}

REVIEW
{results.get('agent4', '')}"""
                    path = os.path.join(DATA_DIR, f'export_{timestamp}.txt')
                    with open(path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    st.success(f"Saved: {path}")
            
            with col2:
                st.download_button(
                    "‚¨áÔ∏è Download",
                    data=results.get('agent3', ''),
                    file_name="linkedin_optimized.txt",
                    use_container_width=True
                )

if __name__ == "__main__":
    main()